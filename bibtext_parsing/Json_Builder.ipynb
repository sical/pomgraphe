{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pybtex.database import parse_file\n",
    "import json\n",
    "from pprint import pprint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# changes names format to a single string (ex: \"Robert Downey Jr.\")\n",
    "\n",
    "def name_filtering(data,test):\n",
    "    for j in test :\n",
    "        dataset = []\n",
    "        if 'author' in test[j].persons:\n",
    "            str = 'author'\n",
    "        elif 'editor' in test[j].persons: \n",
    "            str = 'editor'\n",
    "        else: \n",
    "            continue\n",
    "        for i in test[j].persons[str]:\n",
    "            first = \"\"\n",
    "            middle = \"\"\n",
    "            last = \"\"\n",
    "            line = \"\"\n",
    "            all = \"\"\n",
    "            if i.first_names:\n",
    "                all += i.first_names[0]\n",
    "            if i.middle_names:\n",
    "                all += \" \" + i.middle_names[0]\n",
    "            if i.last_names:\n",
    "                all += \" \" + i.last_names[0]\n",
    "            if i.lineage_names:\n",
    "                all += \" \" + i.lineage_names[0]\n",
    "            dataset.append(all)\n",
    "        data[j] = {'names': dataset, 'year': test[j].fields['year'], 'title': test[j].fields['title']}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates links and nodes \n",
    "\n",
    "def setup(data,ref_list,to_import):\n",
    "    jfile = {}\n",
    "    jfile[\"nodes\"] = []\n",
    "    jfile[\"links\"] = []\n",
    "    for article in data :\n",
    "        to_do = False\n",
    "        for k in data[article]['names']:\n",
    "            if k in ref_list:\n",
    "                to_do = True\n",
    "                break\n",
    "        if to_do:\n",
    "            for i in data[article]['names']:\n",
    "                node = {}\n",
    "                node[\"id\"] = i\n",
    "                node[\"lastColaboration\"] = \"0\"\n",
    "                if i in ref_list:\n",
    "                    node[\"group\"] = find_team(i,to_import)\n",
    "                else:\n",
    "                    node[\"group\"] = \"no team\"\n",
    "                new_node = True\n",
    "                for _node in jfile[\"nodes\"]:\n",
    "                    if _node[\"id\"] == i:\n",
    "                        new_node = False\n",
    "                if new_node:\n",
    "                    jfile[\"nodes\"].append(node)\n",
    "                for j in data[article]['names'] :\n",
    "                    if (i != j) :\n",
    "                        new = True\n",
    "                        for k in jfile[\"links\"]:\n",
    "                            if (k[\"source\"] == j) & (k[\"target\"] == i) :\n",
    "                                new = False\n",
    "                                break\n",
    "                            elif (k[\"source\"] == i) & (k[\"target\"] == j) :\n",
    "                                if data[article]['title'] not in k[\"titles\"]:\n",
    "                                    k['titles'].append(data[article]['title'])\n",
    "                                    k[\"nbLinks\"] += 1\n",
    "                                \n",
    "                                link[\"lastColaboration\"] = max(link[\"lastColaboration\"],data[article]['year'])\n",
    "                                new = False\n",
    "                                break\n",
    "                        if new:\n",
    "                            link = {}\n",
    "                            link[\"source\"] = i\n",
    "                            link[\"target\"] = j\n",
    "                            link[\"nbLinks\"] = 1\n",
    "                            link[\"titles\"] = [data[article]['title']]\n",
    "                            link[\"lastColaboration\"] = data[article]['year']\n",
    "                            jfile[\"links\"].append(link)\n",
    "                                                        \n",
    "                for j in range(len(jfile[\"nodes\"])):\n",
    "                    if jfile[\"nodes\"][j][\"id\"] == i:\n",
    "                        jfile[\"nodes\"][j][\"lastColaboration\"] = max(jfile[\"nodes\"][j][\"lastColaboration\"],data[article]['year'])\n",
    "                        break\n",
    "                    \n",
    "    return jfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    tab = []\n",
    "    tab.append(['{\\\\\\'{e}}','é'])\n",
    "    tab.append(['{\\\\\\'{E}}','É'])\n",
    "    tab.append(['{-}','-'])\n",
    "    tab.append(['{\\\\^{o}}','ô'])\n",
    "    tab.append(['{\\\\\"{e}}','ë'])\n",
    "    tab.append(['{\\\\\"{u}}','ü'])\n",
    "    tab.append(['{\\\\`{e}}','è'])\n",
    "    tab.append(['{\\\\`{o}}','ò'])\n",
    "    tab.append(['{\\\\\"{a}}','ä'])\n",
    "    tab.append(['{\\\\ae}','æ'])\n",
    "    tab.append(['{\\\\ss}','ß'])\n",
    "    tab.append(['{\\\\\"{o}}','ö'])\n",
    "    tab.append(['{\\\\\"{\\\\i}}','ï'])\n",
    "    tab.append(['{\\\\\\'{a}}','à'])\n",
    "    tab.append(['{\\\\^{\\\\i}}','î'])\n",
    "    tab.append(['{\\\\\\'{\\\\i}}','í'])\n",
    "    tab.append(['{\\\\~{n}}','ñ'])\n",
    "    tab.append(['{\\\\c{c}}','ç'])\n",
    "    tab.append(['{\\\\c{C}}','Ç'])\n",
    "    tab.append(['{\\oe}','œ'])\n",
    "    tab.append(['{\\\\`{a}}','à'])\n",
    "    tab.append(['{\\\\(\\\\mathscr{l}\\\\)}','ℓ'])\n",
    "    tab.append(['\\\\emph{delta}','δ'])\n",
    "    tab.append(['{\\\\^{a}}','â'])\n",
    "    tab.append(['{\\\\&}','&'])\n",
    "    tab.append(['{\\\\\\'{o}}','ó'])\n",
    "    tab.append(['{\\\\(\\\\mu\\\\)}','μ'])\n",
    "    tab.append(['{\\\\~{a}}','ã'])\n",
    "    tab.append(['{\\\\\"{O}}','Ö'])\n",
    "    tab.append(['{\\\\^{e}}','ê'])\n",
    "    tab.append(['\\\\{é\\\\}','é'])\n",
    "    \n",
    "    \n",
    "    for article in data :\n",
    "        for pair in tab:\n",
    "            for i in range(len(data[article]['names'])):\n",
    "                data[article]['names'][i] = data[article]['names'][i].replace(pair[0],pair[1])\n",
    "            data[article]['title'] = data[article]['title'].replace(pair[0],pair[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save results in json file\n",
    "\n",
    "def save(jfile):\n",
    "    with open('data.json', 'w') as f:\n",
    "        json.dump(jfile, f)\n",
    "\n",
    "    #pprint(jfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_files():\n",
    "    to_import = []\n",
    "    for x in os.walk(os.getcwd() + \"\\\\bibtex_data\"):\n",
    "        if x[2]:\n",
    "            team_name = x[0].replace(os.getcwd() + \"\\\\bibtex_data\\\\\", '')\n",
    "            data = {'team': team_name, 'persons': []}\n",
    "            for i in x[2]:\n",
    "                i = i.replace('.bib','')\n",
    "                data['persons'].append(i.split('_'))\n",
    "            to_import.append(data)\n",
    "\n",
    "    ref_list = []\n",
    "    for i in range(len(to_import)):\n",
    "        for j in to_import[i]['persons']:\n",
    "            ref_list += [j[1] + ' ' + j[0]]\n",
    "    \n",
    "    return to_import,ref_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_team(name,to_import):\n",
    "    usable_name = list(reversed(name.split(\" \")))\n",
    "    if len(usable_name) > 2:\n",
    "        usable_name = [\" \".join(reversed(usable_name[0:len(usable_name)-1])),usable_name[len(usable_name)-1]]\n",
    "    for team in to_import:\n",
    "        if usable_name in team[\"persons\"]:\n",
    "            return team[\"team\"]\n",
    "    return \"unknown_team\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_data = {}\n",
    "\n",
    "to_import,ref_list = retrieve_files()\n",
    "\n",
    "for team_names in to_import:\n",
    "    for people in team_names['persons']:\n",
    "        data = parse_file('bibtex_data/' + team_names['team'] + '/'+ people[0] + '_' + people[1] + '.bib').entries\n",
    "        filtered_data = name_filtering(filtered_data,data)\n",
    "        clean_data(filtered_data)\n",
    "       \n",
    "jfile = setup(filtered_data,ref_list,to_import)\n",
    "save(jfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
